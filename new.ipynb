# 1. INSTALL DEPENDENCIES
!pip install -q kaggle
!pip install -q tensorflow matplotlib scikit-learn

import os
import zipfile
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score, f1_score
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import ResNet50, MobileNetV2, EfficientNetB0
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, GlobalAveragePooling2D

# 2. UPLOAD KAGGLE JSON
from google.colab import files
files.upload()  # Upload kaggle.json

# 3. SETUP KAGGLE AND DOWNLOAD DATASET
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d abdallahalidev/plantvillage-dataset
!unzip -q plantvillage-dataset.zip -d plantvillage

# 4. SETUP DATA LOADERS
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Image settings
img_size = (224, 224)  # You can change this size based on the model requirements
batch_size = 32

# Data path (you confirmed this path is correct)
data_path = "/content/plantvillage/plantvillage dataset/color"

# ImageDataGenerator with validation split
train_datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2  # 80-20 train-validation split
)

# Training data generator
train_gen = train_datagen.flow_from_directory(
    data_path,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='categorical',
    subset='training',
    shuffle=True,
    seed=42
)

# Validation data generator
val_gen = train_datagen.flow_from_directory(
    data_path,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='categorical',
    subset='validation',
    shuffle=False,
    seed=42
)
# 5. DEFINE ALL MODELS

def create_custom_cnn():
    model = Sequential([
        Conv2D(32, (3, 3), activation='relu', input_shape=img_size + (3,)),
        MaxPooling2D(),
        Conv2D(64, (3, 3), activation='relu'),
        MaxPooling2D(),
        Conv2D(128, (3, 3), activation='relu'),
        MaxPooling2D(),
        Flatten(),
        Dropout(0.5),
        Dense(128, activation='relu'),
        Dense(num_classes, activation='softmax')
    ])
    return model

def create_transfer_model(base_model_fn):
    base_model = base_model_fn(weights='imagenet', include_top=False, input_shape=img_size + (3,))
    base_model.trainable = False
    model = Sequential([
        base_model,
        GlobalAveragePooling2D(),
        Dropout(0.5),
        Dense(num_classes, activation='softmax')
    ])
    return model

models_to_train = {
    "Custom_CNN": create_custom_cnn(),
    "ResNet50": create_transfer_model(ResNet50),
    "MobileNetV2": create_transfer_model(MobileNetV2),
    "EfficientNetB0": create_transfer_model(EfficientNetB0),
}

# 6. TRAIN & EVALUATE MODELS
results = {}

for name, model in models_to_train.items():
    print(f"\nðŸ”§ Training {name}...")
    model.compile(optimizer='adam',
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])
    
    history = model.fit(train_gen, validation_data=val_gen, epochs=5, verbose=1)

    # Evaluate
    val_gen.reset()
    predictions = model.predict(val_gen)
    y_pred = np.argmax(predictions, axis=1)
    y_true = val_gen.classes

    precision = precision_score(y_true, y_pred, average='macro')
    recall = recall_score(y_true, y_pred, average='macro')
    f1 = f1_score(y_true, y_pred, average='macro')
    cm = confusion_matrix(y_true, y_pred)

    # Save
    results[name] = {
        "history": history.history,
        "precision": precision,
        "recall": recall,
        "f1": f1,
        "confusion_matrix": cm,
        "accuracy": history.history['val_accuracy'][-1]
    }

# 7. PLOT RESULTS
for name, res in results.items():
    hist = res['history']
    plt.figure(figsize=(10,4))
    plt.subplot(1,2,1)
    plt.plot(hist['accuracy'], label='Train Acc')
    plt.plot(hist['val_accuracy'], label='Val Acc')
    plt.title(f'{name} Accuracy')
    plt.legend()
    plt.subplot(1,2,2)
    plt.plot(hist['loss'], label='Train Loss')
    plt.plot(hist['val_loss'], label='Val Loss')
    plt.title(f'{name} Loss')
    plt.legend()
    plt.show()

# 8. SHOW METRICS
print("\nðŸ“Š Final Results:")
for name, res in results.items():
    print(f"\n{name}")
    print(f"Accuracy: {res['accuracy']*100:.2f}%")
    print(f"Precision: {res['precision']:.4f}")
    print(f"Recall: {res['recall']:.4f}")
    print(f"F1 Score: {res['f1']:.4f}")
    print("Classification Report:")
    print(classification_report(val_gen.classes, np.argmax(models_to_train[name].predict(val_gen), axis=1), target_names=class_names))

    # Plot confusion matrix
    plt.figure(figsize=(10,8))
    sns.heatmap(res['confusion_matrix'], annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names, cmap='Blues')
    plt.title(f"{name} - Confusion Matrix")
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.show()
